{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d7b0a2-653b-42c7-9550-5aa9c675f77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Output:\n",
      "tensor([[[ 0.1446, -0.0710, -0.0724,  0.0838, -0.0739,  0.0579,  0.0374,\n",
      "          -0.0342,  0.1297,  0.0644,  0.0385,  0.0452,  0.0625,  0.0768,\n",
      "          -0.1009, -0.1196],\n",
      "         [ 0.1863, -0.0836, -0.0405,  0.0899, -0.0179,  0.0057,  0.0133,\n",
      "          -0.0182,  0.1213,  0.1319,  0.0022,  0.0786,  0.0830,  0.1149,\n",
      "          -0.1352, -0.0776],\n",
      "         [ 0.2918, -0.1325, -0.0168,  0.0887,  0.0348, -0.0910,  0.0087,\n",
      "          -0.0142,  0.1455,  0.2207, -0.1024,  0.1624,  0.1736,  0.1900,\n",
      "          -0.2143, -0.0513],\n",
      "         [ 0.2090, -0.0865, -0.0646,  0.0843, -0.0450,  0.0272,  0.0458,\n",
      "          -0.0128,  0.1527,  0.1152,  0.0213,  0.1090,  0.1222,  0.1302,\n",
      "          -0.1688, -0.1232],\n",
      "         [ 0.1120, -0.0535, -0.0451,  0.0841, -0.0424,  0.0626,  0.0174,\n",
      "          -0.0249,  0.0942,  0.0770,  0.0624,  0.0242,  0.0177,  0.0758,\n",
      "          -0.0847, -0.0824]],\n",
      "\n",
      "        [[ 0.0141, -0.0130,  0.0492, -0.0967,  0.0377, -0.0373,  0.0504,\n",
      "          -0.1189, -0.0421, -0.0367, -0.1095, -0.0176, -0.0579,  0.0592,\n",
      "          -0.0011,  0.0465],\n",
      "         [ 0.0243, -0.0350,  0.0442, -0.1092,  0.0787, -0.1267,  0.0156,\n",
      "          -0.0954, -0.0177,  0.0195, -0.1489,  0.0146, -0.0379,  0.0383,\n",
      "           0.0058,  0.1009],\n",
      "         [ 0.0172, -0.0166,  0.0259, -0.1469,  0.0664, -0.0579,  0.0891,\n",
      "          -0.0757,  0.0175, -0.0120, -0.0438,  0.0629, -0.0255,  0.0794,\n",
      "          -0.0500,  0.0392],\n",
      "         [ 0.0200, -0.0036,  0.0464, -0.0661, -0.0112,  0.0176,  0.0594,\n",
      "          -0.1368, -0.0682, -0.0775, -0.1141, -0.0451, -0.0495,  0.0717,\n",
      "          -0.0092,  0.0074],\n",
      "         [ 0.0113, -0.0212,  0.0446, -0.1287,  0.0770, -0.0795,  0.0539,\n",
      "          -0.0951, -0.0086, -0.0023, -0.0896,  0.0218, -0.0541,  0.0561,\n",
      "          -0.0083,  0.0702]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "Attention Weights:\n",
      "tensor([[[0.2130, 0.2105, 0.2420, 0.1710, 0.1635],\n",
      "         [0.2237, 0.1613, 0.1631, 0.2127, 0.2391],\n",
      "         [0.1837, 0.1154, 0.0966, 0.4022, 0.2021],\n",
      "         [0.2012, 0.1487, 0.2561, 0.2412, 0.1527],\n",
      "         [0.2047, 0.1989, 0.1939, 0.1168, 0.2858]],\n",
      "\n",
      "        [[0.2367, 0.1918, 0.1538, 0.1867, 0.2311],\n",
      "         [0.1407, 0.1726, 0.2574, 0.2402, 0.1890],\n",
      "         [0.1542, 0.3149, 0.1715, 0.1670, 0.1924],\n",
      "         [0.2530, 0.1628, 0.1067, 0.1584, 0.3190],\n",
      "         [0.2062, 0.2451, 0.1847, 0.2035, 0.1604]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, embed_dim, head_dim):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.embed_dim = embed_dim  # Input embedding dimension\n",
    "        self.head_dim = head_dim    # Dimension of each attention head\n",
    "\n",
    "        # Linear layers for query, key, and value\n",
    "        self.query = nn.Linear(embed_dim, head_dim, bias=False)\n",
    "        self.key = nn.Linear(embed_dim, head_dim, bias=False)\n",
    "        self.value = nn.Linear(embed_dim, head_dim, bias=False)\n",
    "\n",
    "        # Output linear layer to combine the attended result\n",
    "        self.out_proj = nn.Linear(head_dim, embed_dim, bias=False)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate QK^T / sqrt(d_k)\n",
    "        d_k = K.size(-1)  # Head dimension for scaling\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "\n",
    "        # Apply optional mask (useful for causal/self-attention)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        # Apply softmax to get attention weights\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "        # Multiply with V to get the final attention output\n",
    "        output = torch.matmul(attention_weights, V)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Generate query, key, and value matrices\n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "\n",
    "        # Apply scaled dot-product attention\n",
    "        attention_output, attention_weights = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "\n",
    "        # Project the attention output back to the embedding dimension\n",
    "        output = self.out_proj(attention_output)\n",
    "\n",
    "        return output, attention_weights\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Define input parameters\n",
    "    batch_size = 2  # Number of sequences in a batch\n",
    "    seq_len = 5     # Length of each sequence\n",
    "    embed_dim = 16  # Input embedding dimension\n",
    "    head_dim = 8    # Head dimension for multi-head attention\n",
    "\n",
    "    # Create a random input tensor (batch_size, seq_len, embed_dim)\n",
    "    x = torch.randn(batch_size, seq_len, embed_dim)\n",
    "\n",
    "    # Initialize the attention head\n",
    "    attention_head = AttentionHead(embed_dim, head_dim)\n",
    "\n",
    "    # Run the input through the attention head\n",
    "    output, attention_weights = attention_head(x)\n",
    "\n",
    "    print(\"Attention Output:\")\n",
    "    print(output)\n",
    "    print(\"\\nAttention Weights:\")\n",
    "    print(attention_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04dacdf4-c624-43ad-a380-cfb8d75fb753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=16, out_features=8, bias=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_head.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78dd62-2f4a-4e3f-b1b4-825b388f87db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
